# bilive Settings
[model]
model_type = "append" # Can be pipeline, append, merge

# WARNING!: If you choose "deploy" local inference:
# 1. Please check the VRAM requirements twice!
# 2. Please make sure you have installed the Nvidia GPU driver and can check the cuda via `nvcc -V`!
# WARNING!: If you choose "api":
# due to the limitation of free tier, you should keep every video less than 30 minutes(around)
# which means your MODEL_TYPE should not be "merge".
[asr]
asr_method = "none" # can be "deploy" or "api" or "none"
whisper_api_key = "" # Apply for your own API key at https://console.groq.com/keys
inference_model = "small" # If you choose "deploy", you should download the inference model from https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt

[video]
# You can change the title as you like, eg.
# f"{artist}直播回放-{date}-{title}" - Streamer直播回放-20250328-Live title
# f"{date}-{artist}直播回放" - 20250328-Streamer直播回放
title = "{artist}直播回放-{date}-{title}" # Key words: {artist}, {date}, {title}, {source_link}
description = "{artist}直播回放，直播间地址：{source_link} 内容仅供娱乐，直播中主播的言论、观点和行为均由主播本人负责，不代表录播员的观点或立场。" # Key words: {artist}, {date}, {title}, {source_link}
gift_price_filter = 1 # The gift whose price is less than this value will be filtered, unit: RMB
reserve_for_fixing = false # If encounter MOOV crash error, delete the video or reserve for fixing
upload_line = "auto" # The upload line to be used, default None is auto detect(recommended), if you want to specify, it can be "bldsa", "ws", "tx", "qn", "bda2".

[slice]
auto_slice = false # General control: true or false
slice_duration = 60 # better not exceed 300 seconds
slice_num = 2 # the number of slices
slice_overlap = 30 # the overlap of slices(seconds) see my package https://github.com/timerring/auto-slice-video for more details
slice_step = 1 # the step of slices(seconds)
min_video_size = 200 # The minimum video size to be sliced (MB)
mllm_model = "gemini" # the multi-model LLMs, can be "gemini" or "zhipu" or "qwen"
zhipu_api_key = "" # Apply for your own GLM-4v-Plus API key at https://www.bigmodel.cn/invite?icode=shBtZUfNE6FfdMH1R6NybGczbXFgPRGIalpycrEwJ28%3D
gemini_api_key = "" # Apply for your own Gemini API key at https://aistudio.google.com/app/apikey
qwen_api_key = "" # Apply for your own Qwen API key at https://bailian.console.aliyun.com/?apiKey=1

[cover]
generate_cover = false # whether to generate cover
image_gen_model = "minimax" # the image generation model, can be "minimax" or "siliconflow" or "tencent" or "baidu"
minimax_api_key = "" # Apply for your own Minimax API key at https://platform.minimaxi.com/user-center/basic-information/interface-key
siliconflow_api_key = "" # Apply for your own SiliconFlow API key at https://cloud.siliconflow.cn/i/3Szr5BVg
tencent_secret_id = "" # Apply for your own Tencent Cloud API key at https://console.cloud.tencent.com/cam/capi
tencent_secret_key = "" # Apply for your own Tencent Cloud secret key as above
baidu_api_key = "" # Apply for your own Baidu API key at https://console.bce.baidu.com/iam/key/list
